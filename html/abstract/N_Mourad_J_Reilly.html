<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>
  <head>
    <title>Statistical Signal Processing</title>
		<link rel="stylesheet" type="text/css" href="../../css/ssp.css" />
		<script type='text/javascript' src='../../include/spp_header.js'></script>
  </head>

  <body>
   <a name="top"></a>
    
<table width="85%" border="0" align="center">
  <tr> 
    <td> 
      <!-- Display logo of McMaster ECE Department -->
      <table width="710px" border="0" align="center">
        <tr>
          <td align="center"><img src="../images/home_header.gif" border="0" ></td>
        </tr>
        <tr>
          <td align="center" height="50px"><img src="../images/ssp.jpg"></td>
        </tr>
      </table></td>
  </tr>
  <!-- Dispaly menu on top of the page -->
  <td valign="top"> <table width="100%" align="center" cellpadding="4" cellspacing="4">
        <tr>
        <td><div align="center"> 
            <script type='text/javascript' src='../include/menuinfo.js'></script>
            <script type='text/javascript' src='../include/menu_com.js'></script>
            <br>
          </div></td>
      </tr>
      <tr> 
          <td> <p class = "pub">Minimizing Nonconvex Functions for Sparse Vector 
              Reconstruction</p>
          <em>IEEE Trans. Signal Processing, Vol. 58, No. 7, July 2010 </em><br> 
          <strong>N. Mourad and J. Reilly </strong>
            <p class = "abstract"> <strong>Abstract</strong> &nbsp; In this paper 
              we develop a novel methodology for minimizing a class of non&#8211;convex 
              (concave on the non&#8211; negative orthant) functions for solving 
              under&#8211;determined linear system of equations As = x when the 
              solution vector s is known a priori to be sparse. The proposed technique 
              is based on locally replacing the original objective function by 
              a quadratic convex function which is easily minimized. The resulting 
              algorithm is iterative and is absolutely converging to a fixed point 
              of the original objective function. For a certain selection of convex 
              objective functions, the class of algorithms called Iterative Reweighted 
              Least Squares (IRLS) are shown to be a special case of the proposed 
              methodology. Thus the proposed algorithms are a generalization and 
              unification of the previous methods. In addition, we also propose 
              a new class of algorithms with better convergence properties compared 
              to the regular IRLS algorithms and hence can be considered as enhancements 
              to these algorithms. Since the original objective functions are 
              non-convex, the proposed algorithm is susceptible to convergence 
              to a local minimum. To alleviate this difficulty, we propose a random 
              perturbation technique that enhances the performance of the proposed 
              algorithm. The numerical results show that the proposed algorithms 
              outperform some of the well known algorithms that are usually utilized 
              for solving the same problem.</p>
          <br> </td>
      </tr>
      <tr> 
        <td align="right"> <a class="n" a href="#" onClick="window.history.go(-1)";>go 
          back</a> </td>
      </tr>
      <tr> 
        <td><hr></td>
      </tr>
    </table></td>
  </tr>
</table>


 <!-- Begin Footer -->
		    
<table width="85%" border="0" align="center">
  <!--DWLayoutTable-->
  <tr>
			    
    <td class=breadcrumb align="center"> <a class="n" href="http://www.mcmaster.ca" >&copy; 
      McMaster University 2011</a>&nbsp;&nbsp;| &nbsp; <a class="n" href="../../html/contact/contact.html">Contact 
      Us</a> &nbsp;&nbsp;| &nbsp; <a class="n" href="mailto:spencer@mail.ece.mcmaster.ca">ECE 
      Webmaster</a> <BR>
		          <BR>
		        </td>
		      </tr>
		    </table>

		  </body>

</html>
